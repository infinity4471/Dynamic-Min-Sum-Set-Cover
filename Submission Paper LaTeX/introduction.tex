\section{Introduction}
\label{s:intro}

In \emph{Dynamic Min-Sum Set Cover} ($\DSSC$), we are given a universe $U$ on $n$ elements, a sequence of requests $\cR = (R_1, \ldots, R_T)$, with $R_t \subseteq U$, and an initial permutation $\pi^0$ of the elements of $U$. We aim to maintain a sequence of permutations $(\pi^0, \pi^1, \ldots, \pi^T)$ of $U$, so as to minimize the total cost of updating (or moving from) $\pi^{t-1}$ to $\pi^{t}$ in each time step plus the total cost of covering each request $R_t$ with the current permutation $\pi^t$. The cost of moving from $\pi^{t-1}$ to $\pi^{t}$ is the number of inverted element pairs between $\pi^{t-1}$ and $\pi^t$, i.e., the Kendall Tau distance $\dkt(\pi^{t-1}, \pi^t)$. The cost $\pi^t(R_t)$ of covering a request $R_t$ with a permutation $\pi^t$ is the position of the first element of $R_t$ in $\pi^t$, i.e., $\pi^t(R_t) = \min\{ i \,|\, \pi^t(i) \in R_t \}$. Thus, given $\cR = (R_1, \ldots, R_T)$, we aim to minimize $\sum_{t=1}^T \big( \dkt(\pi^{t-1}, \pi^t) + \pi^t(R_t) \big)$. 
%
%More formally, given $U$ and $\cR = \{ R_1, \ldots, R_T \}$, the goal in $\DSSC$ is to maintain a sequence of permutations $\pi^0, \pi^1, \ldots, \pi^T$ so as to minimize the total moving cost plus the total covering cost: $\sum_{t=1}^T \big( \dkt(\pi^{t-1}, \pi^t) + \pi^t(R_t) \big)$. 

The $\DSSC$ problem is a natural generalization of the (offline version of the) classical \emph{List Update} problem \cite{ST85b}, where $|R_t| = 1$ for all requests $R_t \in \cR$. The offline version of List Update is $\mathrm{NP}$-hard \cite{Amb00}, while it is known that any $5/4$-approximation has to resort to \emph{paid exchanges}, where an element different from the requested one is moved forward to the list \cite{LRR15,tim16}. $\DSSC$ was introduced in \cite{FKKSV20} as the dynamic extension of Min-Sum Set Cover ($\SSC$) \cite{FLT04}, where we aim to compute a single static permutation $\pi$ that minimizes the total covering cost  $\sum_{t=1}^T \pi(R_t)$. \cite{FKKSV20} presented a (simple polynomial-time) online algorithm for $\DSSC$ with competitive ratio between $\Omega(r \sqrt{n})$ and $O(r^{3/2} \sqrt{n})$ for $r$-bounded instances, where all requests have cardinality at most $r$, and posed the polynomial-time approximability of $\DSSC$ as an interesting open question. $\DSSC$ is also related to recently studied time-evolving (a.k.a. multistage or dynamic) optimization problems (e.g., multistage matroid, spanning set and perfect matching maintenance \cite{GTW14}, time-evolving Facility Location \cite{EMS14,Svensson15}), where we aim to maintain a sequence of near-optimal feasible solutions to a combinatorial optimization problem, in response to time-evolving underlying costs, without changing too much the solution from one step to the next. 
%We elaborate on the connections of $\DSSC$ to previous work in Section~\ref{s:related}. 

\paragraph{Motivation.} 
%
$\DSSC$ is motivated by applications, such as web search, news, online shopping, paper bidding, etc., where items are presented to the users sequentially. Then, the item ranking is of paramount importance, because user attention is usually restricted to the first few items in the sequence (see e.g., \cite{StreeterGK09,CKMS01,FSR18,PT18}). If a user does not spot an item fitting her interests there, she either leaves the service (in case of news or online shopping, see e.g., the empirical evidence in \cite{DGMM20}) or settles on a suboptimal action (in case of paper bidding, see e.g., \cite{GP13}). To mitigate such situations and increase user retention, modern online services highly optimize item rankings based on user scrolling and click patterns. Each user $t$ is represented by her set of preferred items (or item categories) $R_t$\,. The goal of the service provider is to continually maintain an item ranking $\pi^t$, so that the current user $t$ finds one of her favorite items at a relatively high position in $\pi^t$. Continual ranking update is dictated by the fact that users with different characteristics and preferences tend to use the online service during the course of the day (e.g., elderly people in the morning, middle-aged people in the evening, young people at the night -- similar patterns apply for people from different countries and timezones). Moreover, different user categories react in nonuniform ways to different trends (in e.g., news, fashion, sports, scientific topics). For consistency and stability, however, the ranking should change neither too much nor too frequently. $\DSSC$ makes the (somewhat simplifying) assumptions that the service provider has a relatively accurate knowledge of user preferences and their arrival order, and that its total cost is proportional to how deep in $\pi^t$ the current user $t$ should reach, before she finds one of her favorite items, and to how much the ranking changes from one user to the next. 

From a theoretical viewpoint, $\DSSC$ was used in \cite{FKKSV20} as a natural benchmark for studying the dynamic competitive ratio of Online Min-Sum Set Cover, where the algorithm updates its permutation online, without any knowledge of future requests. As in $\DSSC$, the objective is to minimize the total moving plus the total covering cost. 

%\subsection{Contribution and Techniques}
%\label{s:contrib}
\paragraph{Contribution and Techniques.}
%
In this work, we initiate a study of the polynomial-time approximability of $\DSSC$. Using a reduction from Set Cover, we show (Theorem~\ref{t:hardness}) that $\DSSC$ does not admit a $c\log n$-approximation, for some absolute constant $c$, unless $\mathrm{P}=\mathrm{NP}$. Moreover our reduction establishes that an $o(r)$-approximation for $r$-bounded instances of $\DSSC$ implies an $o(r)$-approximation for Set Cover, in case each element appears in at most $r$ requests. 

Our main technical contribution is to show that $\DSSC$ can be approximated in polynomial-time within a factor of $O(\log^2 n)$ in general instances, by randomized rounding (Theorem~\ref{t:rand}), and within a factor of $O(r^2)$ in $r$-bounded instances, by deterministic rounding (Theorem~\ref{t:greedy}). %Both results require a novel approach and several key new insights related to the dynamic nature of $\DSSC$. 

For both results, we consider a restricted version of $\DSSC$, inspired by the Move-to-Front (MTF) algorithm for List Update, where in each time step $t$, we can only move a single element of $R_t$ from its position in $\pi^{t-1}$ to the first position of $\pi^t$. Since such a permutation $\pi^t$ coves $R_t$ with unit cost, we now aim to select the element of each $R_t$ moved to front of $\pi^t$, so as to minimize the total moving cost $\sum_{t=1}^T \dkt(\pi^{t-1}, \pi^t)$. It is not hard to see that the optimal cost of serving $\cR$ under the restricted Move-to-Front version of $\DSSC$ is within a factor of $4$ from the optimal cost under the original, more general, definition of $\DSSC$. 

Hence, approximating $\DSSC$ boils down to determining which element of $R_t$ should become the top element of $\pi^{t}$. To this end, we relax permutations to doubly stochastic matrices and consider a Linear Programming relaxation of the restricted Move-to-Front version of $\DSSC$, which we call \emph{Fractional-MTF} (see Definition~\ref{d:frac_MTF}). Given the optimal solution of the aforementioned linear program, which is a sequence of doubly stochastic matrices $(A^0, A^1, \ldots, A^T)$, with $A^0$ corresponding to the initial permutation $\pi^0$, our main technical challenge is to round each doubly stochastic matrix $A^t$ to a permutation $\pi^t$ such that (i) there is an element of $R_t$ at one of the few top positions of $\pi^t$; and (ii) the total moving cost $\sum_{t=1}^T \dkt(\pi^{t-1}, \pi^t)$ of the rounded solution is comparable to the total moving cost $\sum_{t=1}^T \dfr(A^{t-1}, A^t)$ of the optimal solution of Fractional-MTF, where $\dfr$ is a notion of distance equivalent to Spearman's footrule distance on permutations (see Definition~\ref{d:distance_lp}).  %An essential step in formulating Fractional-MTF as a Linear Program is to introduce a notion of distance on doubly stochastic matrices that can be regarded as the fractional version of  

%Given the optimal solution of Fractional-MTF, which is a sequence of doubly stochastic matrices $(A^0, A^1, \ldots, A^T)$, with $A^0$ corresponding to the initial permutation $\pi^0$, our main technical challenge is to round each doubly stochastic matrix $A^t$ to a permutation $\pi^t$ such that (i) there is an element of $R^t$ at one of the few top positions of $\pi^t$; and (ii) the total moving cost $\sum_{t=1}^T \dkt(\pi^{t-1}, \pi^t)$ of the rounded solution is comparable to the total moving cost $\sum_{t=1}^T \dfr(A^{t-1}, A^t)$ of the optimal solution of Fractional-MTF. 

Working towards a randomized rounding approach, we first observe that rounding each doubly stochastic matrix independently may result in a permutation sequence with total moving cost significantly larger than that of Fractional-MTF (see also the discussion after Lemma~\ref{l:relax}). In Theorem~\ref{t:rand}, we show that a dependent randomized rounding with  logarithmic scaling of entries  (Algorithm~\ref{alg:rand_rounding}), similar in spirit with the randomized rounding approach \cite{BGK10,SW11} for Generalized Min-Sum Set Cover, results in an approximation ratio of $O(\log^2 n)$. Interestingly, Algorithm~\ref{alg:rand_rounding} without the logarithmic scaling results in a permutation sequence with the expected moving cost within a factor of $4$ from the optimal moving cost of Fractional-MTF. However, we lose a logarithmic factor in the approximation ratio, because we need to scale up the entries of each doubly stochastic matrix $A^t$, so as to ensure that some element of $R_t$ appears in the few top positions of $\pi^t$ with sufficiently large probability. The other logarithmic factor is lost because there could be a logarithmic number of elements allocated to the same position of the resulting permutation by the randomized rounding. 

Our deterministic rounding of Algorithm~\ref{alg:greedy_rounding} for $r$-bounded request sequences is motivated by the deterministic rounding for Set Cover and Vertex Cover. We observe that in the optimal solution of Fractional-MTF, in each time step $t$, there is some element $e \in R_t$ with $A^{t}_{e1} \geq 1/r$ (i.e., $e$ occupies a fraction of at least $1/r$ of the first position in the ``fractional permutation'' $A^t$). Algorithm~\ref{alg:greedy_rounding} simply moves any such element to the front of $\pi^t$. The most challenging part of the analysis is to establish that for any optimal solution $(A^0, A^1, \ldots, A^T)$ of Fractional-MTF with respect to an $r$-bounded request sequence, there exists a sequence of doubly stochastic matrices $(A^0, \hat{A}^1, \ldots, \hat{A}^T)$ with the entries of each $\hat{A}^t$ being multiples of $1/r$, such that (i) the moving cost of $(A^0, \hat{A}^1, \ldots, \hat{A}^T)$ is bounded from above by the optimal cost of Fractional-MTF; and (ii) each matrix $\hat{A}^t$ contains in the first position the element that Algorithm~\ref{alg:greedy_rounding} keeps in the first position at round $t$, with mass at least $1/r$. Then we show (Lemma~\ref{l:r_integral}) that for any sequence of doubly stochastic matrices $(A^0, \hat{A}^1, \ldots, \hat{A}^T)$ satisfying the above properties, the moving cost of Algorithm~\ref{alg:greedy_rounding} is at most the moving cost of the doubly stochastic matrices,
$\sum_{t=1}^T \dfr(\hat{A}^t,\hat{A}^{t-1})$. The latter is done through the use of an appropriate potential function based on an extension of the Kendall-Tau distance to doubly stochastic matrix with entries being multiples of $1/r$.

A potentially interesting insight %from the analysis of our rounding schemes 
is that the technical reason for the quadratic dependence of our approximation ratios on $\log n$ and $r$ is conceptually similar to the reason for the (best possible) approximation ratio of $4 = 2\cdot 2$ in \cite{FLT04} (see the discussion after Theorem~\ref{t:rand}). Hence, we conjecture that any $o(\log^2 n)$ (resp. $o(r^2)$) approximation to $\DSSC$ must imply a sublogarithmic (resp. $o(r)$) approximation to Set Cover.% (resp. where each element appears at most $r$ times). 

%In addition to making significant progress towards understanding the polynomial-time approximability of $\DSSC$, we believe that the techniques applied to the analysis of our rounding schemes may be of independent interest and may find applications to the design of approximation algorithms for other time-evolving and/or dynamic optimization problems. 

\paragraph{Other Related Work.}
%
The $\SSC$ problem generalizes various $\mathrm{NP}$-hard problems, such as Min-Sum Vertex Cover and Min-Sum Coloring and it is well-studied. Feige, Lovasz and Tetali~\cite{FLT04} proved that the greedy algorithm, which picks in each position the element that covers the most uncovered requests, is a $4$-approximation (that was also implicit in~\cite{BBHST98}) and that no $(4-\varepsilon)$-approximation is possible, unless $\mathrm{P} = \mathrm{NP}$. In Generalized $\SSC$ (a.k.a. \emph{Multiple Intents Re-ranking}), there is a covering requirement $K(R_t)$ for each request $R_t$ and the cost of covering a request $R_t$ is the position of the $K(R_t)$-th element of $R_t$ in the (static) permutation $\pi$. The $\SSC$ problem is the special case where $K(R_t)=1$ for all requests $R_t$. Another notable special case of Generalized $\SSC$ is the Min-Latency Set Cover problem \cite{HL05}, which corresponds to the other extreme case where $K(R_t) = |R_t|$ for all requests $R_t$. Generalized $\SSC$ was first studied by Azar et al.~\cite{AGY09}, who presented a $O(\log r)$-approximation; later $O(1)$-approximation algorithms were obtained~\cite{BGK10,SW11,ISZ14,BBFT20}.

Further generalizations of Generalized $\SSC$ have been considered, such as the Submodular Ranking problem, studied in \cite{AG11}, which generalizes both Set Cover and $\SSC$, and the Min-Latency Submodular Cover, studied by Im et al.~\cite{INZ16}. We refer to~\cite{INZ16,Im16} for a detailed discussion on the connections between these problems and their applications. 

The online version of $\SSC$, which generalizes the famous List Update problem, was studied in \cite{FKKSV20}. They proved that its static deterministic competitive ratio is $\Theta(r)$ and presented a natural  memoryless algorithm, called \emph{Move-all-Equally}, with static competitive ratio in $\Omega(r^2)$ and $2^{O(\sqrt{\log n  \cdot \log r})}$ and dynamic competitive ratio in $\Omega(r \sqrt{n})$ and $O(r^{3/2} \sqrt{n})$-competitive. Subsequently, \cite{FLPS20} considered $\SSC$ from the viewpoint of online learning. Through dimensionality reduction from permutations to doubly stochastic matrices, they obtained randomized (resp. deterministic) polynomial-time online learning algorithms with $O(1)$-regret for Generalized $\SSC$ (resp. $O(r)$-regret for $\SSC$). 

%The online version of $\DSSC$ belongs to a rich family of online problems called \emph{Metrical Task Systems} see e.g., \cite[Chapter~9]{BEY98} and the references therein), which also includes several fundamental online problems (e.g., paging, $k$-server, convex body chasing). 

%The online version of $\DSSC$ generalizes the dynamic List Update problem, which has been extensively studied . The classical \emph{Move-to-Front} (MTF) algorithm, which moves the (unique) element of the request to the first position of the permutation, is known to be $2$-competitive \cite{ST85}. There are several other $2$-competitive algorithms~\cite{Albers98,EY96}. For randomized algorithms, the best known competitive ratio is 1.6~\cite{ASW95} and the best lower bound is 1.50115~\cite{ambuhl2002list}. The offline version of dynamic List Update corresponds to $\DSSC$ with singleton requests. It is $\mathrm{NP}$-hard \cite{Amb00} and can be solved in time $O(2^n (n-1)! T)$ \cite{RW96} and in time $O(2^n 3^{n!} (n!)^2 + nT)$ \cite{Hage07}, i.e., in time exponential in $n$ but polynomial in $T$. 